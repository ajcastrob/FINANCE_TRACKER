import streamlit as st
import google.generativeai as genai
import pandas as pd
from chatbot.contexto import obtener_contexto_financiero

# Configurar la clave API de Google.
genai.configure(api_key=st.secrets["GEMINI_API_KEY"])


# FunciÃ³n para llamar al modelo de Gemini
@st.cache_resource
def cargar_modelo_gemini():
    """Carga el mÃ³delo de gemini y aprovecha el cacheo para no gastar mÃ¡s llamadas"""
    return genai.GenerativeModel(
        "gemini-2.5-flash",
        generation_config={
            "temperature": 0.7,
        },
    )


def generar_respuesta_gemini(
    pregunta_usuario: str, datos_df: pd.DataFrame, historial_conversacion: list = None
) -> str:
    """Generar una respuesta con el mÃ³delo de Gemini"""
    try:
        # Obtener el contexto financiero del dataset
        contexto = obtener_contexto_financiero(datos_df)

        # Crear resumen de transacciones con formato limpio
        # Limitar a las Ãºltimas 100 transacciones para no sobrecargar el prompt
        if len(datos_df) > 100:
            datos_recientes = datos_df.tail(100)
            nota_transacciones = f"\n Mostrando 100 transacciones de {len(datos_df)} transacciones totales.\n"
        else:
            datos_recientes = datos_df
            nota_transacciones = ""

        # Formatear transacciones con saltos de lÃ­nea explÃ­citos.
        transacciones_texto = "TRANSACCIONES RECIENTES:" + nota_transacciones
        for idx, row in datos_recientes.iterrows():
            # formatear la fecha
            if pd.notna(row["fecha"]):
                fecha_str = pd.to_datetime(row["fecha"]).strftime("%Y-%m-%d")
            else:
                fecha_str = "N/A"

            # crear lÃ­nea de transacciÃ³n
            transacciones_texto += f"\n. {fecha_str} | $ {row["cantidad"]:,.2f} |  {row["categoria"]} | {row["descripcion"]}"

        # Contruir el historial de conversaciÃ³n de Gemini
        historial_gemini = []
        if historial_conversacion:
            for msg in historial_conversacion[
                -4:
            ]:  # Solo los Ãºltimos cuatro para no exceder lÃ­mites
                rol = "user" if msg["role"] == "user" else "model"
                historial_gemini.append({"role": rol, "parts": [msg["content"]]})

        # Prompt limpio con formato estructurado.
        prompt_sistema = f"""Eres AdamBot ğŸ’°, un asistente financiero profesional y amigable.
                RESUMEN FINANCIERO DEL USUARIO:
            â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
            - Balance Total: $ {contexto.get('balance_total', 0):,.2f}
            - Ingresos Totales: $ {contexto.get('total_ingresos', 0):,.2f}
            - Egresos Totales: $ {contexto.get('total_egresos', 0):,.2f}
            - Total de Transacciones: {contexto.get('total_transacciones', 0)}

                ÃšLTIMOS 30 DÃAS:
            - Ingresos: $ {contexto.get('ingresos_ultimos_30_dias', 0):,.2f}
            - Egresos: $ {contexto.get('egresos_ultimos_30_dias', 0):,.2f}

            ÃšLTIMA TRANSACCIÃ“N:
            - CategorÃ­a: {contexto.get('ultima_categoria', 'N/A')}
            - Monto: $ {contexto.get('ultima_cantidad', 0):,.2f}
            - Fecha: {contexto.get('ultima_fecha', 'N/A')}

            {transacciones_texto}

            â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
                    INSTRUCCIONES IMPORTANTES:
            1. Responde basÃ¡ndote ÃšNICAMENTE en los datos proporcionados arriba
            2. MantÃ©n tus respuestas concisas: mÃ¡ximo 100 palabras
            3. Usa espacios correctos entre TODAS las palabras y nÃºmeros
            4. Formatea cantidades monetarias como: "$ 1,234.56" (siempre con espacio despuÃ©s del $)
            5. Usa emojis con moderaciÃ³n para hacer la conversaciÃ³n amigable
            6. Si detectas patrones preocupantes, menciÃ³nalos con tacto
            7. Proporciona anÃ¡lisis numÃ©ricos cuando sea relevante

            PREGUNTA DEL USUARIO:
            {pregunta_usuario}
            TU RESPUESTA (recuerda: espacios claros entre palabras):"""

        # Cargar el mÃ³delo de Gemini llamando a la funciÃ³n
        model = cargar_modelo_gemini()

        # Crear una sesiÃ³n con el historial del chat
        chat = model.start_chat(history=historial_gemini)

        # Generar una respuesta
        response = chat.send_message(prompt_sistema)

        # Verificar que la respuesta tenga contenido
        if response.parts:
            texto = response.text
            # Post-procesamiento para garantizar espacios correctos
            texto = texto.replace("$", "$ ")  # Eliminar espacios despuÃ©s de $
            texto = texto.replace("  ", " ")  # Eliminar espacios dobles
            texto = texto.strip()

            # Retornar la respuesta
            return texto
        else:
            return f"âŒ No pude generar una respuesta."
    except Exception as e:
        return f"âŒ Error al procesar pregunta: {str(e)}"
